---
title: "Avocado Dataset Statistical Analysis"
author:
- "Aylanur Cüce 70180101"
- "Selin Şaki 70180118"
- "Gökhan Kaan Kizir 70180145"
- "Pelin Mert 70180744"
output: pdf_document
date: "06/06/2020"
header-includes: 
  - \renewcommand{\and}{\\}
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
options(scipen = 999) # Disabled scientific notation for a smooth graph.
options(width = 80)
```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=64), tidy=TRUE)
```

#### 1. Describe the Data Set statistically. What are the variables? Define the type of each variable (Nominal, ordinal, or interval). Descriptive Statistics for the total number of avocado sold in Atlanta region (Variance, Standard deviation, Range, Percentiles, Quartiles, Measure of Skew. Scatterplot, Box Plot).  
```{r}
library(moments)

printf <- function(...) {
	cat(sprintf(...), "\n")
}
```

Defining a generalized function to calculate fractiles
```{r, tidy=FALSE}
fractile <- function(data_set, n) {
	name <- "Fractile"
	if (n ==   3) name <- "Tertile"
	if (n ==   4) name <- "Quartile"
	if (n ==   5) name <- "Quintile"
	if (n ==   6) name <- "Sextile"
	if (n ==   7) name <- "Septile"
	if (n ==   8) name <- "Octile"
	if (n ==  10) name <- "Decile"
	if (n ==  12) name <- "Duo-decile"
	if (n ==  16) name <- "Hexadecile"
	if (n ==  20) name <- "Ventile"
	if (n == 100) name <- "Percentile"
	for (i in 2:n-1) {
		printf("%s %s = %s", name, i, quantile(data_set, i * (1/n)))
	}
}
```

We define another function to calculate the variance, standard deviation, range and skewness measures.
```{r}
basic_descriptive <- function(data_set) {
	printf("Variance = %s", var(data_set))
	printf("Standard Deviation = %s", sd(data_set))
	range <- range(data_set)
	printf("Range = %s - %s", range[1], range[2])
	fractile(data_set, 4)
	fractile(data_set, 100)
	printf("Skewness = %s", skewness(data_set))
}
```

Now we should read our data and retrieve information about Atlanta region.
```{r}
avocado_data <- read.csv("avocado.csv")

atlanta <- avocado_data[avocado_data[,"region"] == "Atlanta",]
atlanta_total <- atlanta[,"Total.Volume"]
```

We now want to define the data set and the type of each variable:
```{r, echo=FALSE}
printf("The data set describes avacodo sales
       with prices and the amount of units
       in certain regions of America")
printf("Accessed from : https://www.kaggle.com/neuromusic/avocado-prices")
printf("Variables :")
printf("Date         - Interval - The date the entry was recorded at")
printf("AveragePrice - Interval - The average price of an avacado in the entry")
printf("Total Volume - Interval - The total count of avocado sold in the entry")
printf("4046         - Interval - The count of avocados sold with code 4046 in the entry")
printf("4225         - Interval - The count of avocados sold with code 4225 in the entry")
printf("4770         - Interval - The count of avocados sold with code 4770 in the entry")
printf("Total Bags   - Interval - The total bags of avocado sold in the entry")
printf("Small Bags   - Interval - The count of small bags sold in the entry")
printf("Large Bags   - Interval - The count of large bags sold in the entry")
printf("XLarge Bags  - Interval - The count of extra large bags sold in the entry")
printf("type         - Nominal  - Whether the sold avocados are organic or conventional")
printf("year         - Interval - The year the entry was recorded at")
printf("region       - Nominal  - The region where the data entry was located at")
```

Now we can call our function to calculate the measures we want:
```{r}
basic_descriptive(atlanta_total)
```

\newpage
We can plot scatter and boxplot for total number of avocado sold in Atlanta region:  
```{r, echo=FALSE, fig.height=4}
plot(atlanta_total, atlanta[,"AveragePrice"], main = "Total Volume in Atlanta", xlab= "Total Volume", ylab = "Average Price", pch=16)
boxplot(atlanta_total, main = "Total Volume in Atlanta", xlab= "Total Volume", horizontal = T, ylab = "Avocado", col = "blue")
```

\newpage
#### 2. Hypothesis testing for mean (Hint: You need determine test value for the total amount of avocado sold in Atlanta region.)

Import the library to be used and read the data
```{r}
library(data.table)

my_avocado_data <- read.csv("avocado.csv", sep = ",", header = T)
atlanta_data <- subset(my_avocado_data, region == "Atlanta")
atlanta <- atlanta_data$Total.Volume
```

#### 2.1. State the hypothesis.  


H~0~(Null hypothesis): Mean of total amount of avocado sold (in volume) in Atlanta region is equal to 200,000 (test value)  
H~1~(Alternative hypothesis): Mean of total amount of avocado sold (in volume) in Atlanta region is greater than 200,000 (test value).

We define our test value:
```{r}
test_mu <- 200000
```

#### 2.2 Compute the test statistic.

```{r}
t.test(atlanta_total, mu = test_mu, alternative = "greater", var.equal = T, conf.level = 0.95)
```

Here's our t-statistic value:
```{r}
t_value <- (mean(atlanta) - test_mu)/ sqrt(var(atlanta)/nrow(atlanta_data))
print(t_value)
```

#### 2.3. Interpret the results.  
 
t\_value = 4.3424 with df = 337 and p-value = 0.000009 which means 200000 (conf. level = 0.95 then alpha = 0.05)  
Reject null hypothesis in favor of alternative hypothesis.  
Mean of total amount of avocado sold in Atlanta region is greater than 200000.  


\newpage
#### 3. Hypothesis testing for standard deviation (Hint: You need determine test value for the total amount of avocado sold in Atlanta region).

Import the libraries and read the data
``` {r}
library(data.table)
library(TeachingDemos)

my_avocado_data <- read.csv("avocado.csv", sep = ",", header = T)
atlanta_data <- subset(my_avocado_data, region == "Atlanta")
atlanta <- atlanta_data$Total.Volume
```

##### 3.1. State the hypothesis.  
 
H~0~(Null hypothesis): Standard deviation of total amount of avocado sold (in volume) in Atlanta region is equal to 200000 (test value)  
H~1~(Alternative hypothesis): Standard deviation of total amount of avocado sold (in volume) in Atlanta region is greater than 200000 (test value)  
 
We define a test value:
```{r}
test_sigma <- 200000
```

#### 3.2. Compute the test statistic.  

We can apply sigma test from Teaching Demos library:
```{r}
sigma.test(atlanta_total, sigma = test_sigma, sigmasq = test_sigma^2, alternative = "greater", conf.level = 0.95)
```

We also define a Chi-squared value:
```{r}
chisquare_value <- (nrow(atlanta_data) - 1) * (var(atlanta)) / ((test_sigma)^2)
print(chisquare_value)
```

#### 3.3. Interpret the results.  

chisquare\_value = 583.22  with df = 337 and p-value = 0.000000000000001887 (conf. level = 0.95 then alpha = 0.05)  
Reject null hypothesis in favor of alternative hypothesis.  
Standard deviation of total amount of avocado sold in Atlanta region is greater than 200000 (it is 263107.1)  


\newpage
#### 4. Two sample confidence intervals for the means of total amount of avocado sold in Boston region and Atlanta region. 

```{r}
printf <- function(...) {
	cat(sprintf(...), "\n")
}
```

Gather the needed data
```{r}
avocado_data <- read.csv("avocado.csv")

boston <- avocado_data[avocado_data[,"region"] == "Boston",]
boston_total <- boston[,"Total.Volume"]

atlanta <- avocado_data[avocado_data[,"region"] == "Atlanta",]
atlanta_total <- atlanta[,"Total.Volume"]
```

Define the confidence level
```{r}
confidence = 0.95
```

Find the sample size, mean and variances for the two samples
```{r}
n_one <- length(boston_total)
n_two <- length(atlanta_total)

mean_one <- mean(boston_total)
mean_two <- mean(atlanta_total)

var_one <- var(boston_total)
var_two <- var(atlanta_total)
```

Calculate the degrees of freedom and the t-value
```{r}
v <- ((var_one / n_one + var_two / n_two)^2) / (((var_one / n_one)^2) / (n_one - 1) + ((var_two / n_two)^2) / (n_two - 1))

t <- (-qt((1 - confidence)/2, df=v))
```

Calculate the margin of error from the t-value and the estimate from the means
```{r}
std_err <- sqrt((var_one / n_one) + (var_two / n_two))

estimate <- mean_one - mean_two
```

We can now display our calculations and calculate the confidence interval
```{r}
printf("mean_one=%s", mean_one)
printf("mean_two=%s", mean_two)
printf("estimate=%s", estimate)
printf("t=%s", t)
printf("v=%s", v)
printf("Confidence interval:")
printf(sprintf("%.2f - %.2f * %.2f < mu_one - mu_two < %.2f + %.2f * %.2f", estimate, t, std_err, estimate, t, std_err))
printf(sprintf("%.4f - %.4f < mu_one - mu_two < %.4f + %.4f", estimate, t * std_err, estimate, t * std_err))
printf(sprintf("%s < mu_one - mu_two < %s", estimate - t * std_err, estimate + t * std_err))
```

\newpage
#### 5. Two sample hypothesis testing for means of total amount of avocado sold in Boston region and Atlanta region.  

Import the library and read the data
```{r}
library(data.table)

avo <- as.data.table(read.csv("avocado.csv"))
atlanta <- avo[avo$region == "Atlanta", ]$Total.Volume
boston <- avo[avo$region == "Boston", ]$Total.Volume
```

We will apply t-test. Assume that each groups are approximately normally distributed with equal variances.

##### 5.1. State the hypothesis.  
 
H~0~: There is NO significant difference between total sales (in volume) for Boston and Atlanta regions.  
H~1~: There is a significant difference between total sales (in volume) for Boston and Atlanta regions.  
Notice that this test is two-tailed.  
 
##### 5.2. Compute the test statistic.

Perform the test:
```{r}
t.test(atlanta, boston, paired = F, alternative = "two.sided", var.equal = T, conf.level = 0.95)
```

The t-value, p-values and the critical t-value as follows:
```{r}
t_value <- (mean(atlanta)-mean(boston))/sqrt(var(atlanta)/338 + var(boston)/338)
print(t_value)
2*pt(t_value,df=674) #p-val
2*pnorm(t_value) #p-val-normal
t_critical <- qt(0.025, df= 674)
print(t_critical)
```
We could also obtain this value from t.test function output.  

##### 5.3. Interpret the results.  

t\_value = -1.217 with df = 674 and p = 0.224. p > 0.025 (two-tailed test, conf. level = 0.95, then alpha = 0.05)  
We fail to reject null hypothesis.  
There is no significant difference between means for Boston and Atlanta regions.  


\newpage
#### 6. Regression Analysis: ‘4046’ and ‘Total bags’ in Boston region.  

Import the library and obtain the data
```{r}
library(data.table)

avo <- as.data.table(read.csv("avocado.csv"))
at <- avo[region == "Atlanta"]
```

##### 6.1. Obtain the equation of the regression line.  

```{r}
model <- lm(Total.Bags ~ X4046, data = at )
print(model)
```

Our formula should be stated as:  
Total Bags = 20554.7389 + 0.4376 * (Avocados with PLU sticker 4046)  

##### 6.2. Graph the line on a scatter diagram.  

We can plot the data using the following code:
```{r, fig.height=3}
library(ggplot2)
ggplot(at, aes(X4046, Total.Bags)) + ggtitle("Type 4046 vs. Total Bags") + xlab("Avocado Type 4046")+ ylab ("Total Bags") + 
  geom_point() + geom_smooth(method = lm, se= FALSE) +   theme(plot.title = element_text(hjust = 0.5))
```

The regular plot function can also be used
```{r, fig.height=3}
plot(at$X4046, at$Total.Bags, main = "Type 4046 vs. Total Bags",
     xlab = "Avocado Type with PLU 4046", ylab = "Total Bags", pch = 16) 
abline(model, col = "blue")
```

Other relevant plots can be acquired as such:
```{r, fig.height=4}
plot(model)
```

##### 6.3. Interpret R-squared value  

We call the summary function:
```{r}
summary(model)
```

R-squared value is used to interpret how well our model fits the data.  
R-squared takes a value between 0 and 1. Here the summary gives us two different values for R-squared: multiple and adjusted.  
Multiple R-squared: 0.4503, Adjusted R-squared: 0.4487  
We are interested in adjusted R-squared value. Multiple R-squared includes a penalty for multiple linear regression models.  
0.4487 value means that our model is not able to explain the variability (only partially). A value closer to 1 would be preferred.  
We can observe that from Residual standard error value as well: 74,800. RSE value is relatively high, which means that the linear model fits our data poorly. The values deviate from our regression line by 74,800 units.  

Also the percentage error for RSE is calculated by:  
```{r}
sigma(model) * 100 / mean(at$Total.Bags)
```

##### 6.4. Hypothesis testing for the slope and intercept.  

##### 6.4.1. Hypothesis testing on the slope

H~0~: The coefficient is equal to zero (no correlation between Total Bags and Avocado type 4046.)  
H~1~: The coefficient is NOT equal to zero. (There is a correlation between Total Bags and Avocado type 4046.)  

```{r}
b1 <- model$coefficients[2]
n <- nrow(at)
SSE <- sum((at$Total.Bags - mean(at$Total.Bags))^2) - b1*(sum((at$X4046 - mean(at$X4046))* (at$Total.Bags - mean(at$Total.Bags))))
s <- sqrt(SSE / (n-2))
sxx <- sum((at$X4046 - mean(at$X4046))^2)
# t-value we get from the test:
t_slope <- (b1) / (s/ sqrt(sxx))
# our critical t value is: (%95 confidence interval)
t_critical <- qt(0.975, df = 336)
```
t\_slope > t\_slope\_critical, falls into critical region. Therefore we reject H0, the b1 coefficient cannot be equal to 0. (There's a correlation.)

##### 6.4.2. Hypothesis testing on the intercept

H~0~: The b0 coefficient (intercept) is equal to 0.  
H~1~: The b0 coefficient (intercept) is different than 0.  
```{r}
b0 <- model$coefficients[1]
denom <- sqrt(sum((at$X4046)^2/ (n*sxx)))
t_intercept <- (b0) / (s*denom)
```

t\_intercept = 3.667606 > t\_critical = 1.967, falls into critical region.  
Therefore we reject H0, the intercept cannot be equal to 0.  

We can also check the t-values from summary(model), under the "Coefficients" table, which also confirms our results.  

```{r, echo=FALSE}
# ADDITIONAL - REMOVE
#regression <- summary(model) 
# coefficients <- regression$coefficients
# beta_estimate <-coefficients["X4046", "Estimate"]
#stderror <- coefficients["X4046", "Std. Error"]
# regression_t <- beta_estimate / stderror
# regression_p <- 2*pt(-abs(regression_t), df=nrow(at)-ncol(at))
# print(regression_t)
# Again, using t-value for our hypothesis is 16.59131. 
# It simply tells us that the coefficient cannot be equal to zero. 
# Checking our summary model, we can see that P-value is extremely small and falls into critical region ( <alpha = 0.05) We can reject H0.
```
